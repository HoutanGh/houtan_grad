{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from value import Value\n",
    "from neural_network import MLP\n",
    "from loss import MSE, MAE, CSE\n",
    "\n",
    "mse_loss = MSE()\n",
    "mae_loss = MAE()\n",
    "cse_loss = CSE()\n",
    "\n",
    "y_pred = [Value(0.9), Value(0.2), Value(0.7)]\n",
    "y_true = [Value(1.0), Value(0.0), Value(1.0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: Value(data=0.04666666666666667, grad=0)\n",
      "MAE: Value(data=0.2, grad=0)\n",
      "Cross-Entropy: Value(data=0.22839300363692283, grad=0)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Calculate losses\n",
    "mse = mse_loss(y_pred, y_true)\n",
    "mae = mae_loss(y_pred, y_true)\n",
    "cross_entropy = cse_loss(y_pred, y_true)\n",
    "\n",
    "# Print results\n",
    "print(\"MSE:\", mse)\n",
    "print(\"MAE:\", mae)\n",
    "print(\"Cross-Entropy:\", cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neural_network import MLP  # Assuming this is your file name\n",
    "from value import Value  # Assuming this is your file name\n",
    "\n",
    "# Define an MLP with custom activation functions across layers\n",
    "mlp = MLP(\n",
    "    n_in=5,               # Input size: 5 features\n",
    "    n_outs=[10, 8, 1],    # Neurons per layer\n",
    "    non_lins=['relu', 'tanh', '']  # Activation functions for each layer\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Layer of [ReluNeuron(5), ReluNeuron(5), ReluNeuron(5), ReluNeuron(5), ReluNeuron(5), ReluNeuron(5), ReluNeuron(5), ReluNeuron(5), ReluNeuron(5), ReluNeuron(5)], Layer of [TanhNeuron(10), TanhNeuron(10), TanhNeuron(10), TanhNeuron(10), TanhNeuron(10), TanhNeuron(10), TanhNeuron(10), TanhNeuron(10)], Layer of [LinearNeuron(8)]]\n"
     ]
    }
   ],
   "source": [
    "print(mlp.layers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output of forward pass: Value(data=0.7235274526212041, grad=0)\n"
     ]
    }
   ],
   "source": [
    "# Optionally, test the forward pass to confirm the model works\n",
    "inputs = [Value(1.0) for _ in range(5)]  # Example input: 5 features\n",
    "output = mlp(inputs)\n",
    "\n",
    "# Print the output of the forward pass\n",
    "print(\"Output of forward pass:\", output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "grad_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
